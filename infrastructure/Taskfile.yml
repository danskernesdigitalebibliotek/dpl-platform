# DPL Platform Infrastructure automation
#
# Provisions and configures Azure infrastructure and support software that is
# required by the DPL Platform.
version: '3'

# Pull in defaults that are used across the tasks.
dotenv:
  - "task/defaults.env"

# Any task that uses these variables must have a dependency on the _req_env
# task.
vars:
  # The current environment.
  platform_env: "{{.DPLPLAT_ENV}}"
  # The root directory for the environment.
  dir_env: "environments/{{.platform_env}}"
  # Root of the Terraform-configuration for the environment.
  dir_infra: "environments/{{.platform_env}}/infrastructure"
  # Root of the Terraform-configuration for the github organization.
  dir_env_repos: "environments/{{.platform_env}}/env_repos"
  # Root of the configurations for the environment.
  dir_configuration: "environments/{{.platform_env}}/configuration"
  # Root of the lagoon-configurations for the environment.
  dir_lagoon: "environments/{{.platform_env}}/lagoon"
  # The suffix domain we will use when constructing urls
  global_environment_suffix: "dpl.reload.dk"

tasks:
    default:
      silent: true
      cmds:
        - task -l

    # Internal task for initializing Terraform.
    _infra:terraform:init:
      dir: "{{.dir_infra}}"
      cmds:
        - terraform init

    infra:provision:
      deps: [_req_env, _infra:terraform:init]
      desc: Provision infrastructure for an environment
      summary: |
        Use Terraform to provision the infrastructure for an environment.
      dir: "{{.dir_infra}}"
      cmds:
        - terraform apply

    infra:keyvault:secret:set:
      deps: [_req_env, _infra:terraform:init]
      desc: Sets a keyvault secret
      cmds:
        # Don't print secrets
        - silent: true
          cmd: az keyvault secret set
              --subscription "{{.AZURE_SUBSCRIPTION_ID}}"
              --name "{{.SECRET_KEY}}"
              --vault-name
                $(
                  terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)"
                )
              --value "{{.SECRET_VALUE}}"
              --query id -o tsv

      preconditions:
      - sh: "[ ! -z ${SECRET_KEY} ]"
        msg: "Env variable SECRET_KEY is not set or empty."
      - sh: "[ ! -z ${SECRET_VALUE} ]"
        msg: "Env variable SECRET_VALUE is not set or empty."

    _env_repos:terraform:init:
      dir: "{{.dir_env_repos}}"
      cmds:
        - terraform init

    env_repos:provision:
      deps: [_req_env, _env_repos:terraform:init]
      desc: Provision infrastructure for an environment
      summary: |
        Use Terraform to provision the repositories for our environments.
      env:
        GITHUB_TOKEN:
          sh: az keyvault secret show
              --subscription "{{.AZURE_SUBSCRIPTION_ID}}"
              --name github-infra-admin-pat
              --vault-name
                $(
                  terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)"
                )
              --query value -o tsv
      cmds:
        - cmd: cd {{.dir_env_repos}} && terraform apply

    cluster:auth:
        deps: [_req_env]
        desc: "Authenticate against AKS and setup a functional kubecontext."
        dir: "{{.dir_infra}}"
        vars:
          CLUSTER_NAME:
            sh: terraform output -json | jq --raw-output ".cluster_name.value | select (.!=null)"
          RESOURCEGROUP_NAME:
            sh: terraform output -json | jq --raw-output ".resourcegroup_name.value | select (.!=null)"
        status:
          - "[ $(kubectl config view --output jsonpath='{.current-context}') == '{{.CLUSTER_NAME}}' ] || exit 1"
        cmds:
          - az aks get-credentials --subscription {{.AZURE_SUBSCRIPTION_ID}} --resource-group {{.RESOURCEGROUP_NAME}} --name {{.CLUSTER_NAME}}
        preconditions:
          - sh: "[ ! -z {{.AZURE_SUBSCRIPTION_ID}} ]"
            msg: "Env variable AZURE_SUBSCRIPTION_ID is not set or empty."

    support:provision:cert-manager:
      deps: [cluster:auth]
      summary: Set the DIFF environment variable to any value to switch to diffing instead of an actual upgrade.
      desc: Install and configure cert-manager
      env:
        DIFF: "{{.should_diff}}"
      cmds:
        - task/scripts/provision-cert-manager.sh

    support:provision:ingress-nginx:
      deps: [cluster:auth]
      summary: Set the DIFF environment variable to any value to switch to diffing instead of an actual upgrade.
      desc: Install and configure ingress-nginx
      env:
        INGRESS_IP:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".ingress_ip.value | select (.!=null)"
        RESOURCE_GROUP:
          sh: terraform  -chdir={{.dir_infra}} output -json | jq --raw-output ".resourcegroup_name.value | select (.!=null)"
      cmds:
        - task/scripts/provision-ingress-nginx.sh

    lagoon:provision:core:
      deps: [cluster:auth]
      desc: Install and configure Lagoon core
      env:
        # Collect the values we'll render into the values-file for the chart.
        KEYCLOAK_ADMIN_PASS:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keycloak_admin_pass_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
        HARBOR_ADMIN_PASS:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".harbor_admin_pass_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
        LAGOON_FILES_API_URL: https://files.lagoon.{{.platform_env}}.{{.global_environment_suffix}}
        LAGOON_FILES_HOSTNAME:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".lagoon_files_blob_storage_client_access_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
        LAGOON_FILES_ACCESS_KEY:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".lagoon_files_blob_storage_client_access_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
        LAGOON_FILES_SECRET_KEY:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".lagoon_files_blob_storage_client_secret_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
        LAGOON_FILES_BUCKET:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".lagoon_files_blob_storage_container_name.value | select (.!=null)"
        BAAS_STORAGE_ACCESS_KEY:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".backup_blob_storage_client_access_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
        BAAS_STORAGE_SECRET_KEY:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".backup_blob_storage_client_secret_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
        CHART_VERSION_LAGOON_CORE:
          sh: source "{{.dir_lagoon}}/lagoon-versions.env" && echo $VERSION_LAGOON_CORE
      cmds:
        - |
          envsubst '$HARBOR_ADMIN_PASS $KEYCLOAK_ADMIN_PASS $LAGOON_FILES_API_URL $LAGOON_FILES_ACCESS_KEY $LAGOON_FILES_BUCKET $LAGOON_FILES_SECRET_KEY $BAAS_STORAGE_ACCESS_KEY $BAAS_STORAGE_SECRET_KEY' \
          < "{{.dir_lagoon}}/lagoon-core-values.template.yaml" \
          > "{{.dir_lagoon}}/lagoon-core-values.yaml"
        # Setup the namespace manually to control eg. labels on the namespace.
        - kubectl apply -f {{.dir_lagoon}}/lagoon-core-namespace.yaml
        - helm repo add lagoon https://uselagoon.github.io/lagoon-charts/
        - |
          helm upgrade --install --namespace lagoon-core \
          -f {{.dir_lagoon}}/lagoon-core-values.yaml lagoon-core \
          lagoon/lagoon-core
      preconditions:
      - sh: "[ ! -z ${KEYCLOAK_ADMIN_PASS} ]"
        msg: "Could not extract the password for the keycloak admin from keyvault."
      - sh: "[ ! -z ${HARBOR_ADMIN_PASS} ]"
        msg: "Could not extract the password for the harbor admin from keyvault."

    lagoon:cli:config:
      deps: [cluster:auth]
      desc: Configure a lagoon cli with the knowledge of a lagoon core.
      summary: |
        In order for the cli to auth your public ssh-key must have been added to
        the core and must be available to ssh eg via "eval $(ssh-agent); ssh-add"
      vars:
        ssh_loadbalancer_ip:
          sh: kubectl get -o jsonpath='{.status.loadBalancer.ingress[0].ip}' -n lagoon-core service lagoon-core-ssh
      status:
        - test -f {{.HOME}}/.lagoon.yml

      cmds:
        - |
            lagoon config add --graphql https://api.lagoon.{{.platform_env}}.{{.global_environment_suffix}}/graphql \
            --ui https://ui.lagoon.{{.platform_env}}.{{.global_environment_suffix}} \
            --hostname {{.ssh_loadbalancer_ip}} \
            --port 22 \
            --lagoon {{.platform_env}}
        - lagoon config default --lagoon {{.platform_env}}
        - lagoon login
        - lagoon whoami
      preconditions:
      - sh: "[ ! -z {{.ssh_loadbalancer_ip}} ]"
        msg: "Could not determine IP of the ssh-endpoint for Lagoon. The Kubernetes lagoon-core/lagoon-core-ssh service may not have been provisioned yet."

    lagoon:provision:harbor:
      deps: [cluster:auth]
      desc: Install an instance of Harbor into a Lagoon cluster.
      env:
        HARBOR_ADMIN_PASS:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".harbor_admin_pass_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv

      cmds:
        - |
          envsubst '$HARBOR_ADMIN_PASS' \
          < "{{.dir_lagoon}}/harbor-values.template.yaml" \
          > "{{.dir_lagoon}}/harbor-values.yaml"
        # Setup the namespace manually to control eg. labels on the namespace.
        - kubectl apply -f {{.dir_lagoon}}/harbor-namespace.yaml
        - helm repo add harbor https://helm.goharbor.io
        # From the official installation guide:
        #   We are currently using Harbor version 1.5.2. A recent update to Harbor breaks the API.
        - |
          helm upgrade --install --namespace harbor \
          --wait -f {{.dir_lagoon}}/harbor-values.yaml --version=1.5.2 \
          harbor harbor/harbor
      preconditions:
      - sh: "[ ! -z ${HARBOR_ADMIN_PASS} ]"
        msg: "Could not extract the password for the Harbor admin from keyvault."

    lagoon:provision:remote:
      deps: [cluster:auth]
      desc: Install and configure Lagoon remote
      env:
        # Fetch a number of variables we'll need to add to a values-file.
        SSH_LOADBALANCER_IP:
          sh: kubectl get -o jsonpath='{.status.loadBalancer.ingress[0].ip}' -n lagoon-core service lagoon-core-ssh
        RABBITMQ_PASS:
          sh: kubectl -n lagoon-core get secret lagoon-core-broker -o jsonpath="{.data.RABBITMQ_PASSWORD}" | base64 -d
        HARBOR_ADMIN_PASS:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".harbor_admin_pass_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
        SQL_HOSTNAME:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".sql_hostname.value | select (.!=null)"
        SQL_SERVERNAME:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".sql_servername.value | select (.!=null)"
        SQL_USER:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".sql_user.value | select (.!=null)"
        SQL_PASSWORD:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".sql_password_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
      cmds:
        # Render the variables we've collected into a values file we can install.
        - |
          envsubst '$SSH_LOADBALANCER_IP $RABBITMQ_PASS $HARBOR_ADMIN_PASS $SQL_HOSTNAME $SQL_SERVERNAME $SQL_USER $SQL_PASSWORD' \
          < "{{.dir_lagoon}}/lagoon-remote-values.template.yaml" \
          > "{{.dir_lagoon}}/lagoon-remote-values.yaml"
        # Setup the namespace manually to control eg. labels on the namespace.
        - kubectl apply -f {{.dir_lagoon}}/lagoon-remote-namespace.yaml
        # Add the lagoon helm repo and install or upgrade the chart.
        - helm repo add lagoon https://uselagoon.github.io/lagoon-charts/
        - |
          helm upgrade --install --namespace lagoon \
          -f {{.dir_lagoon}}/lagoon-remote-values.yaml lagoon-remote \
          lagoon/lagoon-remote
      preconditions:
      - sh: "[ ! -z ${RABBITMQ_PASS} ]"
        msg: "Could not extract the password for the rabbitmq admin from Kubernetes."
      - sh: "[ ! -z ${SSH_LOADBALANCER_IP} ]"
        msg: "Could not determine IP of the load balancer. The lagoon-core/lagoon-core-ssh service may not have been provisioned yet."
      - sh: "[ ! -z ${HARBOR_ADMIN_PASS} ]"
        msg: "Could not extract the password for the Harbor admin from keyvault."

    lagoon:add:registry-credentials:
      deps: [lagoon:cli:config]
      desc: Adds image registry pull-credentials to a project

      vars:
        # Collect the values we'll need for a graphql invocation.
        lagoon_hostname_api:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".lagoon_hostname_api.value | select (.!=null)"
        cluster_api_url:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".cluster_api_url.value | select (.!=null)"
        lagoon_domain_base:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".lagoon_domain_base.value | select (.!=null)"

        # Prepare the mutation.
        mutation: |
          {
            "query": "
            mutation addContainerRegistryEnv {
              addEnvVariable(
                input:{
                  type:PROJECT,
                  typeId:{{.PROJECT_ID}},
                  scope:CONTAINER_REGISTRY,
                  name:\"GITHUB_REGISTRY_CREDENTIALS\",
                  value:\"{{.REGISTRY_PASSWORD}}\"
                }
              ) {
                id
              }
            }
          "}

      # Send the mutation request against graphql, using the bearer token passed
      # by the user.
      cmds:
        - |
          curl \
            -H 'Content-Type: application/json' \
            -H "Authorization: Bearer {{.USER_TOKEN}}" \
            -d '{{.mutation | replace "\n" ""}}' \
            https://{{.lagoon_hostname_api}}/graphql

      preconditions:
      - sh: "[ ! -z {{.lagoon_hostname_api}} ]"
        msg: "Could not determine the api hostname for Lagoon from Kubernetes"
      - sh: "[ ! -z {{.cluster_api_url}} ]"
        msg: "Could not determine the hostname for the Kubernetes API"
      - sh: "[ ! -z {{.lagoon_domain_base}} ]"
        msg: "Could not determine the Lagoon base domain"
      - sh: "[ ! -z {{.USER_TOKEN}} ]"
        msg: "Missing USER_TOKEN"
      - sh: "[ ! -z {{.REGISTRY_PASSWORD}} ]"
        msg: "Missing REGISTRY_PASSWORD"
      - sh: "[ ! -z {{.PROJECT_ID}} ]"
        msg: "Missing PROJECT_ID"

    lagoon:add:cluster:
      deps: [cluster:auth]
      desc: Add a Kubernetes cluster (Lagoon Remote) to the Lagoon Core.
      summary: |
       You must provide a valid bearer token for a lagoon user via the USER_TOKEN environment variable.
       It can be found under the token property in $HOME/.lagoon.yml after you've done a lagoon login

      vars:
        # Collect the values we'll need for a graphql invocation.
        lagoon_hostname_api:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".lagoon_hostname_api.value | select (.!=null)"
        cluster_api_url:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".cluster_api_url.value | select (.!=null)"
        lagoon_domain_base:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".lagoon_domain_base.value | select (.!=null)"
        builddeploy_token:
          sh: "kubectl -n lagoon describe secret $(kubectl -n lagoon get secret | grep kubernetes-build-deploy | awk '{print $1}') | grep token: | awk '{print $2}'"

        # Prepare the mutation.
        mutation: |
          {
          "query": "mutation addKubernetes {
              addKubernetes(input:
                {
                  id: 1,
                  name: \"lagoon\",
                  consoleUrl: \"{{.cluster_api_url}}\",
                  token: \"{{.builddeploy_token}}\",
                  routerPattern: \"${environment}.${project}.{{.lagoon_domain_base}}\"
                }
              )
              {id}
            }"
          }

      # Send the mutation request against graphql, using the bearer token passed
      # by the user.
      cmds:
        - |
          curl \
            -H 'Content-Type: application/json' \
            -H "Authorization: Bearer {{.USER_TOKEN}}" \
            -d '{{.mutation | replace "\n" ""}}' \
            https://{{.lagoon_hostname_api}}/graphql

      preconditions:
      - sh: "[ ! -z {{.lagoon_hostname_api}} ]"
        msg: "Could not determine the api hostname for Lagoon from Kubernetes"
      - sh: "[ ! -z {{.cluster_api_url}} ]"
        msg: "Could not determine the hostname for the Kubernetes API"
      - sh: "[ ! -z {{.lagoon_domain_base}} ]"
        msg: "Could not determine the Lagoon base domain"
      - sh: "[ ! -z {{.builddeploy_token}} ]"
        msg: "Could not determine the build-deploy token from Kubernetes"
      - sh: "[ ! -z {{.USER_TOKEN}} ]"
        msg: "Missing USER_TOKEN"

    lagoon:project:add:
      desc: Add a project to a lagoon remote
      deps: [lagoon:cli:config]
      cmds:
        # - We assume that there will only be a single remote pr core, so we
        #   hardcode --openshift (aka remote) to 1.
        # - We deploy the main and develop branch
        # - We configure the main branch to be the production environment,
        #   This primarily means that develop will auto-idle
        - |
            lagoon add project \
            --gitUrl {{.GIT_URL}} \
            --openshift 1 \
            --productionEnvironment main \
            --branches "^(main|develop)$" \
            --project {{.PROJECT_NAME}}
        - task: lagoon:project:deploykey
      preconditions:
      - sh: "[ ! -z {{.GIT_URL}} ]"
        msg: "Env variable GIT_URL is not set or empty."
      - sh: "[ ! -z {{.PROJECT_NAME}} ]"
        msg: "Env variable PROJECT_NAME is not set or empty."

    lagoon:project:deploykey:
      desc: Gets the deployment key for a project
      deps: [lagoon:cli:config]
      cmds:
        - lagoon get project-key --project {{.PROJECT_NAME}}
      preconditions:
      - sh: "[ ! -z {{.PROJECT_NAME}} ]"
        msg: "Env variable PROJECT_NAME is not set or empty."

    support:provision:bulk-storage:
      deps: [cluster:auth]
      summary: Set the DIFF environment variable to any value to switch to diffing instead of an actual upgrade.
      desc: Install and configure a bulk storage class
      env:
        STORAGE_ACCOUNT_NAME:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".storage_account_name.value | select (.!=null)"
        STORAGE_ACCOUNT_KEY:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".storage_primary_access_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
        RESOURCE_GROUP:
          sh: terraform  -chdir={{.dir_infra}} output -json | jq --raw-output ".resourcegroup_name.value | select (.!=null)"
      cmds:
        - task/scripts/provision-bulk-storage.sh

    support:provision:loki-promtail:
      deps: [cluster:auth]
      summary: Set the DIFF environment variable to any value to switch to diffing instead of an actual upgrade.
      desc: Install and configure Promtail and Loki
      env:
        STORAGE_ACCOUNT_NAME:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".monitoring_storage_account_name.value | select (.!=null)"
        STORAGE_ACCOUNT_KEY:
          sh: az keyvault secret show --subscription "{{.AZURE_SUBSCRIPTION_ID}}" --name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".monitoring_primary_access_key_name.value | select (.!=null)") --vault-name $(terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".keyvault_name.value | select (.!=null)") --query value -o tsv
        STORAGE_CONTAINER_NAME:
          sh: terraform -chdir={{.dir_infra}} output -json | jq --raw-output ".monitoring_blob_storage_container_name.value | select (.!=null)"
      cmds:
        - task/scripts/provision-loki-promtail.sh

    support:provision:grafana:
      deps: [cluster:auth]
      summary: Set the DIFF environment variable to any value to switch to diffing instead of an actual upgrade.
      desc: Install and configure Grafana
      cmds:
        - task/scripts/provision-grafana.sh

    support:provision:prometheus:
      deps: [cluster:auth]
      summary: Set the DIFF environment variable to any value to switch to diffing instead of an actual upgrade.
      desc: Install and configure Prometheus
      cmds:
        - task/scripts/provision-prometheus.sh

    support:provision:
      deps: [cluster:auth]
      desc: Install and configure the support tools Lagoon and DPL Platform builds on
      summary: Set the DIFF environment variable to any value to switch to diffing instead of an actual upgrade.
      dir: "{{.dir_configuration}}"
      vars:
        DIFF_COMMAND: '{{empty .DIFF | ternary "" "diff"}}'
      cmds:
        - task: support:provision:cert-manager
        - task: support:provision:ingress-nginx
        - task: support:provision:bulk-storage
        - task: support:provision:prometheus
        - task: support:provision:loki-promtail
        - task: support:provision:grafana

    site:deploy:
      desc: Runs the a dpladm deploy of a site
      summary: Run the task without additional variables to see required arguments
      dir: "dpladm"
      cmds:
        - bin/deploy-release.sh

    _req_env:
      preconditions:
      - sh: "[ ! -z {{.DPLPLAT_ENV}} ]"
        msg: "Env variable DPLPLAT_ENV is not set or empty."
      - sh: "[ -d {{.dir_env}} ]"
        msg: "Could not find directory {{.dir_env}}"
      - sh: "[ -d {{.dir_infra}} ]"
        msg: "Could not find directory {{.dir_infra}}"
      - sh: "[ -d {{.dir_configuration}} ]"
        msg: "Could not find directory {{.dir_configuration}}"

